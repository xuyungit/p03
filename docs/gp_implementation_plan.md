# 蓝图

直接落地的蓝图，实现 Kriging/GP 的系统方案讲清楚，便下面按「目标—数据—模型—训练—评估—不确定性—对比实验—扩展」八个板块给出步骤与决策点。参考现有的bridge_nn.py的实现。实现灵活的表格类数据的训练。模型的输入输出可以灵活定义，使用正则表达式的方式指定从训练数据的哪些column用作输入，哪些用作输出。复用模型的评价指标计算和评价可视化。

0. 目标与约束

目标
	•	用高斯过程家族（Kriging/GP）构建你的替代模型（surrogate），在精度与不确定性估计上与当前 NN 做对比。
	•	你的数据：N=8000，输入 dₓ=19，输出 dᵧ=71。

约束
	•	经典 GP 训练复杂度 O(N³)；N=8000 时不可直接用标准Kriging/GP。
	•	需要：稀疏/变分近似 + 多任务处理 + 输出降维 才能“既能跑又好用”。

1. 数据与预处理
	1.	数据划分

	•	训练/验证 = 从当前训练数据csv中85/15划分。保证样本分布一致，防止泄漏。

	2.	标准化

	•	输入 X：z-score（按训练集均值/方差）；
	•	输出 Y：z-score（每一维独立标准化，便于多任务权重均衡）。

	3.	输出降维（强烈推荐）

	•	对 71 维输出做 PCA（或 PLS 回归型降维），保留 95–98% 方差，得到 k（通常 8–15）。
	•	后续只拟合 k 个主成分，推理后再 逆PCA 重构回 71 维。
	•	好处：显著降训练与内存负担；同时让多任务相关性变“可压缩”。


2. 模型族与架构选择（从易到难的三档）

A 档（首选基线）：PCA + k 个独立的稀疏变分 GP (SVGP)
	•	对每个主成分 yⱼ 训练一个 SVGP；核函数用 RBF/Matérn + ARD（自动相关性，能做输入选择）；
	•	每个 SVGP 选诱导点 m∈[300, 800]；小批量训练（mini-batch 对 N=8000 有意义）；
	•	简单稳健、易调参；是与 NN 对比的首个可靠基线。

B 档（更强的多任务）：PCA + 多任务 GP（ICM/LMC 核）
	•	建一个多输出 GP，共享输入核（ARD）+ 学习任务协方差（捕捉输出相关性）；
	•	适合 PC 之间仍显著相关的情况；计算更复杂，但样本效率高。
	•	诱导点与 A 档相当；需要成熟实现（如 GPyTorch/GPflow 的多任务变分）。

C 档（非线性更强）：DKL（Deep Kernel Learning）
	•	前端用一个小 NN 做特征映射 φ(X)，后端接 GP（可仍是 SVGP/多任务）；
	•	既保留 GP 的不确定性，又提升对复杂非线性的表达；
	•	训练更难，需要分段学习率/先冻后放策略与更强正则。

建议路线：先 A 档打通 → 若全局指标接近或优于 NN，再尝试 B 档；若遇到强非线性再上 C 档。

3. 关键超参与默认值（给你开箱即用的“起跑线”）
	•	核函数：RBF（先用）或 Matérn-5/2（更鲁棒）；都用 ARD（每个输入一个长度尺度）。
	•	诱导点 m：500（起步），做灵敏度试验 m=300/500/800。
	•	优化目标：变分 ELBO / 负对数似然（NLL）最小化。
	•	优化器：Adam（1e-2 → 1e-3 余弦退火），核超参可配合自然梯度/分组学习率。
	•	批大小：256–1024（按显存/内存调）。
	•	早停：验证集 NLL 或 RMSE 不再下降（耐心 10–20 个 epoch）。
	•	稳定化：核长度尺度、噪声方差用对数域参数化；对角抖动（jitter）1e-6~1e-4。

4. 训练流程（逐步可操作）
	1.	做 PCA：Y→(Z₁…Z_k)，记录均值/方差/投影矩阵，测试时复用。
	2.	建 A 档模型：为每个 Zⱼ 建 SVGP（相同核族、不同参数）；
	3.	诱导点初始化：对 X 做 k-means 取 m 个中心（更稳定），或从训练集中按密度采样；
	4.	训练：
	•	先只训练似然噪声+核长度尺度（其余冻结）若干步，让模型“收住”；
	•	然后全参联合训；
	•	记录验证集 NLL / RMSE；保存最佳 checkpoint。
	5.	推理：得到 Z 的均值与方差 → 逆 PCA 重构回 71 维的均值与协方差对角（近似）。
	6.	可视化：关键输出维（或物理关切的指标）画预测±置信带，对比 NN 的点估计。

5. 评估指标与不确定性校准

点估计
	•	每维 MAE/RMSE/R²；
	•	物理关键维度做单独报表（Top-K），其余做加权平均（按工程重要度或量纲归一化后平均）。

不确定性
	•	预测分布（均值±σ），统计 置信区间覆盖率：
	•	90% 置信区间应覆盖 ≈90% 的真实点（校准良好）；
	•	校准曲线（预测分位 vs 经验分位）与 NLL；
	•	必要时做 温度缩放/方差重标定（在验证集上优化一个缩放因子），提升校准度。

速度
	•	训练时长、单样本推理延迟（CPU/GPU）；
	•	记录显存峰值；为上线评估提供依据。

6. 与神经网络的公平对比清单
	•	同一数据划分与标准化；
	•	同一输出空间：建议 NN 也在 PCA 空间（k 维）回归 + 逆 PCA 重构，确保任务难度一致；
	•	统一指标：MAE/RMSE/R²/NLL/覆盖率；
	•	同等资源限制：如总训练时长或算力预算接近；
	•	统计显著性：多次重启（≥3 次），报告均值±标准差；对关键指标做配对 t 检验。

7. 灵敏度与可解释性（加分项）
	•	ARD 长度尺度：从 GP 的 ARD 参数中读取“每个输入维度的重要性”（长度尺度越小，越敏感）。
	•	全局敏感性（可选）：在 A 档 SVGP 的代理上做 Sobol 指数（对 PCA 主成分或对重构后的关键输出维），量化主/总效应；
	•	对比 NN 的输入重要性（如基于梯度/SHAP），两边交叉验证物理一致性。

8. 常见坑位与规避
	•	输出降维过激：PCA 方差阈值别太低（95–98%），否则逆映射误差影响结论。
	•	噪声项过小：会导致过拟合与数值不稳定；允许各任务（主成分）有独立噪声。
	•	诱导点太少：拟合欠佳；太多则训练慢且易不稳。先 500 做灵敏度。
	•	异方差：若不同区域噪声不同，考虑输入依赖噪声（更复杂）或分区建模。
	•	分布漂移：确保测试集与训练集分布一致；否则报告不确定性失配并给出外推警示。

9. 结论性决策树（你可以照此推进）
	1.	起步：PCA→k≈10；A 档（独立 SVGP, m=500, ARD）；完成一版完整评估。
	2.	若精度接近或优于 NN，且校准更好：
	•	升级到 B 档（ICM/LMC 多任务）；
	•	或固定 A 档做工程上线（NN 在线推断 + GP 做离线校准/复核）。
	3.	若低于 NN：
	•	尝试 DKL（小 NN + GP）；
	•	增大 m；
	•	检查输出 PCA 阈值与输入标准化/异常值。
	4.	交付：选择“性能/成本/校准”最平衡的一档为基线；另外保留 GP 输出的置信区间供决策使用。

10. 可扩展方向（按需选用）
	•	分组多任务：如果 71 维按物理可分组（如跨间、测点、量纲），每组建一个多任务 GP。
	•	层次核/分层 GP：先建结构级变量（温度、沉降）对输出的 GP，再对残差建局部 GP。
	•	物理先验：将已知的线性/单调关系编码到核函数（例如对某些维度使用有向核、周期核等）。
	•	主动学习：用 GP 的方差引导再采样（选择不确定性最大的点重跑 FEM），最少试验达最大收益。


